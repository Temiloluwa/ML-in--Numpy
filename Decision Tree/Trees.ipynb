{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        self._tree_type: 1 stands for classification, 0 stands for regression\n",
    "        \n",
    "        \"\"\"\n",
    "        self._is_leaf        = False\n",
    "        self._left_child     = None\n",
    "        self._right_child    = None\n",
    "        self._split_feature  = None\n",
    "        self._split_rule     = None\n",
    "        self._max_leaf_size  = 1\n",
    "        self._tree_type      = 1\n",
    "    \n",
    "    \n",
    "    def __call__(self,X,y):\n",
    "        if not _self._is_leaf:\n",
    "            return self.split(X,y)\n",
    "        \n",
    "        \n",
    "    def split(self,X,y):\n",
    "        n_samples,n_features = X.shape\n",
    "        #choose the class to predict for, other classes are negative\n",
    "        positive_class       = Y[0]\n",
    "        lowest_gini          = math.inf\n",
    "        best_split           = []\n",
    "        \n",
    "        if self.stop_criterion(X,Y,self._tree_type):\n",
    "            self._leaf = Counter(Y).most_common(1)[0][0]\n",
    "            self._is_leaf = True\n",
    "            return self\n",
    "        else:\n",
    "            if self._tree_type == 1:\n",
    "                for feat in range(n_features):\n",
    "                    feat          = X[:,i]\n",
    "                    unique_values = np.unique(feat)\n",
    "                    mids          = self.midpoints(unique_values)\n",
    "\n",
    "                    for val in mids:\n",
    "                        split  = self.make_split_rule(X,feat,val)\n",
    "                        weighted_gini = compute_gini(y,split)\n",
    "\n",
    "                        \n",
    "\n",
    "                        if weighted_gini < lowest_gini:\n",
    "                            lowest_gini = weighted_gini\n",
    "                            best_split  = split\n",
    "                            self.feature     = i\n",
    "                            self.split_rule  = val\n",
    "            \n",
    "    \n",
    "    \n",
    "    def compute_gini(y,split):\n",
    "        #y indices that are true for criterion\n",
    "        true_criterion = y[split]\n",
    "        false_criterion = y[~split]\n",
    "        \n",
    "        below_posi_class_prob = np.sum(true_criterion == positive_class)/len(true_criterion)\n",
    "        below_neg_class_prob  = 1 -  below_posi_class_prob\n",
    "\n",
    "        above_posi_class_prob = np.sum(false_criterion == positive_class)/len(false_criterion)\n",
    "        above_posi_class_prob  = 1 -  above_posi_class_prob\n",
    "\n",
    "        below_gini = 1 -  below_posi_class_prob**2 - below_neg_class_prob**2\n",
    "        above_gini = 1 -  above_posi_class_prob**2 - above_posi_class_prob**2\n",
    "\n",
    "        weigh_below  = len(below_criterion)/len(Y)\n",
    "        weigh_above  = len(above_criterion)/len(Y)\n",
    "\n",
    "        weighted_gini = weigh_below*below_gini + weigh_above * above_gini\n",
    "        return weighted_gini\n",
    "    \n",
    "    \n",
    "    def midpoints(x):\n",
    "        #returns a array with midvalues of 2 consequtive array elements\n",
    "        mid = np.empty(len(x)-1)\n",
    "        for i in range(len(x)-1):\n",
    "            mid[i] = (x[i] + x[i+1])/2\n",
    "        return mid\n",
    "\n",
    "\n",
    "    def stop_criterion(X,y,tree_type):\n",
    "        #stop splitting if leaf is <= _max_leaf_size\n",
    "        if len(X) <= self._max_leaf_size:\n",
    "            return True\n",
    "        \n",
    "        if tree_type == 1:\n",
    "            #data belongs to the same class\n",
    "            if np.prod(y == y[0]):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    \n",
    "    def make_split_rule(X,feat,val):\n",
    "        #return indices of values less than splitting value\n",
    "        return X[:, feat] < val\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
